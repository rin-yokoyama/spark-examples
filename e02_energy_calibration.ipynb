{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95500194-eb51-4f15-8642-775655d5f4da",
   "metadata": {},
   "source": [
    "# Energy calibration\n",
    "このノートでは、検出器のraw ADCの値をch毎に線形関数でキャリブレーションし、エネルギー情報に変換する。\n",
    "キャリブレーションパラメータはCSVファイルで準備済みとする。\n",
    "\n",
    "- data/clover_data.parquet:\n",
    "こちらは、クローバー型ゲルマニウム検出器3台からなるデータで、各検出器に4つの読み出しチャンネルがあり、\n",
    "合計12chとなっている。\n",
    "\n",
    "- ClvCalib.csv: キャリブレーションパラメータ\n",
    "\n",
    "## ファイルを開く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72423407-0b98-4fca-9583-5aae20fafcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+---+----+\n",
      "|           ts|  cfd| ch| adc|\n",
      "+-------------+-----+---+----+\n",
      "|1657567439657|23504|  8|1348|\n",
      "|1657568832534| 5435|  6|6750|\n",
      "|1657569292316|12850|  2| 744|\n",
      "|1657569301206|14372|  7| 432|\n",
      "|1657569615821|11872| 11| 900|\n",
      "+-------------+-----+---+----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.parquet(\"./data/clover_data.parquet\")\n",
    "df_select = df.select(\"ts\",\"cfd\",\"ch\",\"adc\")\n",
    "df_select.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d575e5-1f04-4dcc-bfc6-1aeca2bc1855",
   "metadata": {},
   "source": [
    "とりあえず\"ch\"と\"adc\"列だけセレクト\n",
    "## 整数値を実数値に変換する。\n",
    "raw ADCの値は整数値なので、0から1の乱数を足して実数値にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f78068b3-53ab-4b9d-a8e4-7cbb5e5e5ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+---+----+------------------+\n",
      "|           ts|  cfd| ch| adc|          adc_real|\n",
      "+-------------+-----+---+----+------------------+\n",
      "|1657567439657|23504|  8|1348| 1348.639293189631|\n",
      "|1657568832534| 5435|  6|6750| 6750.340310900506|\n",
      "|1657569292316|12850|  2| 744|  744.286927331077|\n",
      "|1657569301206|14372|  7| 432|432.28702890550653|\n",
      "|1657569615821|11872| 11| 900| 900.5425011924168|\n",
      "+-------------+-----+---+----+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_real = df_select.withColumn(\"adc_real\", F.col(\"adc\")+F.rand())\n",
    "df_real.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64113b65-6a8c-48b7-a2e4-3aa3980e03dc",
   "metadata": {},
   "source": [
    "## CSVからキャリブレーションパラメータのデータフレームを作る\n",
    "CSVファイルがあるとする。\n",
    "```csv\n",
    "ch,p0,p1\n",
    "0,0.2149837759,0.0803461538\n",
    "1,0.1280723048,0.2546962\n",
    "...\n",
    "```\n",
    "spark.read.csv() でCSVからデータフレームを作成。\n",
    "`header=True`は一行目を列の名前として読むオプション。\n",
    "`inferSchema=True`はデータをstringではなく、推論した型で読み込むオプション。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "647b358d-9fc4-48ef-aba3-819d11c6eb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+\n",
      "| ch|                  p0|                 p1|\n",
      "+---+--------------------+-------------------+\n",
      "|  0|        0.2149837759|       0.0803461538|\n",
      "|  1|        0.1280723048|          0.2546962|\n",
      "|  2|       -0.1933825665|       0.2941007359|\n",
      "|  3|        0.0611566264|       0.0929934353|\n",
      "|  4|       -0.0563791084|       0.2946970847|\n",
      "|  5|        0.0371477634|       0.1212543693|\n",
      "|  6| -0.3015558027966563|0.29948038289716816|\n",
      "|  7|-0.09316673031071332|0.28713228807294117|\n",
      "|  8|   65.26576358770785|0.13040375588633496|\n",
      "|  9| 0.07402471776299535|0.34475015560367683|\n",
      "| 10| 0.03482990048200918| 0.3121818201909335|\n",
      "| 11|0.005223987900080829|0.30955157952139184|\n",
      "+---+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_df = spark.read.csv(\"./ClvCalib.csv\", header=True, inferSchema=True)\n",
    "param_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469c491-811c-47bd-92b4-0ee634f34b8d",
   "metadata": {},
   "source": [
    "## ch番号が一致するパラメータを元のデータフレームにくっつける。\n",
    "- join(): 二つのデータフレームを`on=`で指定した条件を満たす行同士で結合する。`how=\"inner\"`は両方のデータフレームの行が存在するものだけ出力、`how=\"outer\"`は片方が存在しない行も残す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf8e3c48-dbc0-4ee8-bc94-ce22e3621ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+----+------------------+--------------------+-------------------+\n",
      "| ch|           ts|  cfd| adc|          adc_real|                  p0|                 p1|\n",
      "+---+-------------+-----+----+------------------+--------------------+-------------------+\n",
      "|  8|1657567439657|23504|1348| 1348.639293189631|   65.26576358770785|0.13040375588633496|\n",
      "|  6|1657568832534| 5435|6750| 6750.340310900506| -0.3015558027966563|0.29948038289716816|\n",
      "|  2|1657569292316|12850| 744|  744.286927331077|       -0.1933825665|       0.2941007359|\n",
      "|  7|1657569301206|14372| 432|432.28702890550653|-0.09316673031071332|0.28713228807294117|\n",
      "| 11|1657569615821|11872| 900| 900.5425011924168|0.005223987900080829|0.30955157952139184|\n",
      "+---+-------------+-----+----+------------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "calib_df = df_real.join(param_df, on=[\"ch\"], how=\"inner\")\n",
    "calib_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aff7ee-a2dc-4537-a43b-4f2c5215cab9",
   "metadata": {},
   "source": [
    "p0、p1の列に、ch番号に対応する値が入った。\n",
    "## パラメータを使ってエネルギーに変換\n",
    "ここまでできればあとは新しくadc_calを定義するだけ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3986177-4b93-4a78-b676-df5ab3d58830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+----+------------------+--------------------+-------------------+------------------+\n",
      "| ch|           ts|  cfd| adc|          adc_real|                  p0|                 p1|           adc_cal|\n",
      "+---+-------------+-----+----+------------------+--------------------+-------------------+------------------+\n",
      "|  8|1657567439657|23504|1348| 1348.639293189631|   65.26576358770785|0.13040375588633496| 241.1333927555278|\n",
      "|  6|1657568832534| 5435|6750| 6750.340310900506| -0.3015558027966563|0.29948038289716816| 2021.292945191876|\n",
      "|  2|1657569292316|12850| 744|  744.286927331077|       -0.1933825665|       0.2941007359|218.70195048231957|\n",
      "|  7|1657569301206|14372| 432|432.28702890550653|-0.09316673031071332|0.28713228807294117|124.03039698358103|\n",
      "| 11|1657569615821|11872| 900| 900.5425011924168|0.005223987900080829|0.30955157952139184| 278.7695776581576|\n",
      "+---+-------------+-----+----+------------------+--------------------+-------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "calib_df = calib_df.withColumn(\"adc_cal\", F.expr(\"p0 + adc_real * p1\"))\n",
    "calib_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c78c8-0e07-4c25-a53d-c9f2e56cf28e",
   "metadata": {},
   "source": [
    "## ファイルに書き出す\n",
    "- write.parquet(): parquetファイルにデータフレームを書き出す。\n",
    "- mode(\"overwrite\"): ファイルが存在する場合、上書きする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b3df68e-6911-4184-82e4-c27d070e38da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "calib_df.select(\"ts\",\"ch\",\"cfd\",\"adc_cal\").write.mode(\"overwrite\").parquet(\"./data/clover_caldata.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
